<div align=center>

# âš¡ï¸ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation [ICML 2025]

[![arXiv](https://img.shields.io/badge/arXiv-2502.14637-b31b1b?style=flat&logo=arxiv)](https://arxiv.org/abs/2502.14637)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Model-orange?style=flat&logo=huggingface)](https://huggingface.co/AngxiaoYue/ReQFlow/tree/main)
[![Checkpoint](https://img.shields.io/badge/Download-Checkpoint-brightgreen?style=flat&logo=google-drive)](https://drive.google.com/drive/folders/1HboOCWcE7KeNMkAZGR7Cq4wLQ8UhUKXy?usp=sharing)
[![Project Page](https://img.shields.io/badge/Project-Website-blue?style=flat&logo=github)]()
[![Try Demo](https://img.shields.io/badge/Try%20Demo-Online-orange?style=flat&logo=render)](https://your-demo-url.onrender.com)

</div>

<p align="center">
  <img src="assets/combined_protein_flow_2x3_whiteBG.gif" alt="Protein Flow Animation" autoplay loop>
</p>

## ğŸ“Œ Citation
If you find this work useful for your research, please consider citing it. ğŸ˜Š
```bibtex
@misc{yue2025reqflowrectifiedquaternionflow,
      title={ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation}, 
      author={Angxiao Yue and Zichong Wang and Hongteng Xu},
      year={2025},
      eprint={2502.14637},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.14637}, 
}
```

## ğŸ”¥ News
* `2025/05/02` ğŸ’¥ <span style="color:red"><b>ReQFlow is accepted by ICML 2025ï¼ï¼ğŸ‰ğŸ‰</b></span>
* `2025/02/24` ğŸ’¥ Our model weights are hosted on [Hugging Face](https://huggingface.co/AngxiaoYue/ReQFlow/tree/main) and [Google Drive](https://drive.google.com/drive/folders/1HboOCWcE7KeNMkAZGR7Cq4wLQ8UhUKXy?usp=sharing) now ğŸ˜Š.
* `2025/02/20` ğŸ’¥ We release our work [ReQFlow](https://arxiv.org/abs/2502.14637) for efficient and high-quality protein backbone generation!


## ğŸ§© Introduction
Our <span style="color:red">**ReQFlow**</span> achieves <span style="color:red">**state-of-the-art (SOTA)**</span> performance in protein backbone generation while requiring significantly fewer sampling steps and substantially reducing inference time. For example, it is <span style="color:red">**37Ã—**</span> faster than RFDiffusion and <span style="color:red">**62Ã—**</span> faster than Genie2 when generating a backbone of length 300, demonstrating both its effectiveness and efficiency.
<!-- <p align="center">
  <img src="assets/scheme_reqflow.png" width="64.4%">
  <img src="assets/log_speed_10_v2.png" width="30%">
</p>
<p align="center">
  <img src="assets/prot_vis.png" width="95%">
</p> -->
<p align="center" style="margin-bottom: -2.8px;">
  <img src="assets/scheme_reqflow.png" width="64.4%">
  <img src="assets/log_speed_10_v2.png" width="30%">
</p>
<p align="center" style="margin-top: 0px;">
  <img src="assets/prot_vis.png" width="95%">
</p>


## âš’ï¸ Installation
We recommend using [mamba](https://mamba.readthedocs.io/en/latest/).
If using mamba then use `mamba` in place of `conda`.

``` cmd
conda env create -f reqflow-env.yml

conda activate reqflow-env

pip install torch==2.8.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129
pip install torch_geometric
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.8.0+cu129.html

pip install --upgrade deepspeed

# Install local package.
# Current directory should be ReQFlow/
pip install -e .
```

## ğŸš€ Quick Inference
Our model weights are available for download on [Hugging Face](https://huggingface.co/AngxiaoYue/ReQFlow/tree/main) or [Google Drive](https://drive.google.com/drive/folders/1HboOCWcE7KeNMkAZGR7Cq4wLQ8UhUKXy?usp=sharing). You can also use your own weights. If using ours, please organize the directory as follows:
```
ReQFlow
â”œâ”€â”€ ckpts
â”‚   â”œâ”€â”€ qflow_pdb
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â””â”€â”€ qflow_pdb.ckpt
â”‚   â”œâ”€â”€ qflow_scope
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â””â”€â”€ qflow_scope.ckpt
â”‚   â”œâ”€â”€ reqflow_pdb_rectify
â”‚   â”‚   â”œâ”€â”€ config.yaml
â”‚   â”‚   â””â”€â”€ reqflow_pdb_rectify.ckpt
â”‚   â””â”€â”€ reqflow_scope_rectify
â”‚       â”œâ”€â”€ config.yaml
â”‚       â””â”€â”€ reqflow_scope_rectify.ckpt
```
The inference configurations are available in `configs/inference_unconditional.yaml`, where you can conveniently specify the inference settings.
``` yaml
inference:
  task: unconditional
  ckpt_path: ./ckpts/reqflow_pdb_rectify/reqflow_pdb_rectify.ckpt # path to ckpts
  inference_subdir: ./inference_outputs/run_${now:%Y-%m-%d}_${now:%H-%M-%S} # path to inference outputs
  pmpnn_dir: ./ProteinMPNN
  pt_hub_dir: ./.cache/torch/ # path to ESMFold
  num_gpus: 4

  samples:
    min_length: 100
    max_length: 300 # We recommend < 500
    length_step: 50 # sampling on length (100,150,200,250,300)
    samples_per_length: 50
    seq_per_sample: 8 # num. of seq. generated by ProteinMPNN

  interpolant:
    sampling:
      num_timesteps: 500
      do_sde: False
    rots:
      sample_schedule: exp
```
Once you have specified the configurations, you can run inference using the following command:
```cmd
python -W ignore experiments/inference_se3_flows.py -cn inference_unconditional
```
During inference, we evaluate results using the **ProteinMPNN** and **ESMFold** following [FrameDiff](https://github.com/jasonkyuyim/se3_diffusion). The outputs will be saved as follows,
```
inference_outputs
â””â”€â”€ expriment_name                      # Default is date time of inference
    â”œâ”€â”€ config.yaml                     # Config used during inference
    â””â”€â”€ length_100                      # Sampled length 
        â”œâ”€â”€ sample_0                    # Sample ID for length
        â”‚Â Â  â”œâ”€â”€ noise.pdb               # First sample, i.e., noise
        â”‚Â Â  â”œâ”€â”€ sample.pdb              # Final sample
        â”‚Â Â  â”œâ”€â”€ self_consistency        # Self consistency results        
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ esmf                # ESMFold predictions using ProteinMPNN sequences
        â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sample_0.pdb
        â”‚Â Â  â”‚Â Â  â”‚   â”œâ”€â”€ ...
        â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ sample_8.pdb
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ parsed_pdbs.jsonl   # Parsed chains for ProteinMPNN
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sample.pdb
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sc_results.csv      # Summary metrics CSV 
        â”‚Â Â  â”‚Â Â  â””â”€â”€ seqs                
        â”‚Â Â  â”‚Â Â      â””â”€â”€ sample.fa       # ProteinMPNN sequences
        â”‚Â Â  â””â”€â”€ x0_traj_1.pdb           # x_0 model prediction trajectory
        â””â”€â”€ sample_1                    # Next sample
```
<p align="center">
  <img src="assets/Self-Consistency.png" width="95%">
</p>

Based on this `inference_outputs`, we can compute Designability, Diversity and Novelty. More evaluation details to reproduce the paper results are [here](analysis/README.md).
## ğŸ“– Train from Scratch
### Data preparation
We train our models on Protein Data Bank (PDB) and SCOPe dataset, seperately. For PDB dataset, we reprocessed from PDB using the steps described in the [FrameDiff](https://github.com/jasonkyuyim/se3_diffusion), and detailed procedure is also available [here](data/README.md). We also provide a demo PDB dataset in `data` folder to help you test or debug. For SCOPe, we directly downloaded using the [link](https://zenodo.org/records/12776473?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6Ijg2MDUzYjUzLTkzMmYtNDRhYi1iZjdlLTZlMzk0MmNjOGM3NSIsImRhdGEiOnt9LCJyYW5kb20iOiIwNjExMjEwNGJkMDJjYzRjNGRmNzNmZWJjMWU4OGU2ZSJ9.Jo_xXr6-PpOzJHUEAuSmQJK72TMTcI49SStlAVdOHoI2wi1i59FeXnogHvcNioBjGiJtJN7UAxc6Ihuf1d7_eA) provided by [FrameFlow](https://github.com/microsoft/protein-frame-flow/tree/main?tab=readme-ov-file). Tha dataset path is set in `configs/_datasets.yaml`.
### QFlow
Similar to inference, you can simply control your training settings using the yaml files in `configs`. Take training QFlow on PDB dataset as an example, we speicfy the configurations in `configs/train_pdb_base.yaml`,
``` yaml
data:
  dataset: pdb
  rectify: False 

  sampler:
    # Setting for 80GB GPUs
    max_batch_size: 128
    max_num_res_squared: 1000000
  
  experiment:
    is_training: True
    debug: False
    num_devices: 4
    warm_start: null # keep it null on first stage
    warm_start_cfg_override: True
    training:
      aux_loss_t_pass: 0.50
    wandb:
      name: reqflow_train_pdb_base
      project: reqflow
  checkpointer: # where to save checkpoints
    dirpath: ./ckpts/${experiment.wandb.project}/${experiment.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}
    save_last: True
    save_top_k: -1
```
And make sure configs in `_datasets.yaml` is set following instructions [here](data/README.md).

The according training command is
```cmd
python -W ignore experiments/train_se3_flows.py -cn train_pdb_base
```
### ReQFlow
One of our key contributions is **rectifying** the SE(3) generation trajectories in Euclidean/**Quaternion** space to accelerate inference and enhance the designability of the generated protein backbones. We recitify the QFlow model with the generated noise-sample pairs (see `noise.pdb` and `sample.pdb` in `inference_outputs`).

We construct the rectify dataset by converting the generated `.pdb` files into a compatible format. You can follow instructions [here](data/README.md) to do it. 

Once the rectify dataset is obtained, the training pipeline remains the same as QFlow. The configurations can be found in `configs/train_pdb_rectify.yaml`, and make sure `experiment.warm_start` is set to the ckpt you get from first stage training. The command to run it is:
```cmd
python -W ignore experiments/train_se3_flows.py -cn train_pdb_rectify
```

The training of SCOPe dataset is the same as PDB dataset.

## ğŸ‘ Acknowledgments
Thanks to [FrameFlow](https://github.com/microsoft/protein-frame-flow?tab=readme-ov-file), [FrameDiff](https://github.com/jasonkyuyim/se3_diffusion), [FoldFlow](https://github.com/DreamFold/FoldFlow) for their great work and codebase, which served as the foundation for developing ReQFlow.
## ğŸ“§ Contact Us
If you have any question, please feel free to contact us via [angxiaoyue@ruc.edu.cn](mailto:angxiaoyue@ruc.edu.cn) or [zichongwang@ruc.edu.cn](mailto:zichongwang@ruc.edu.cn).

